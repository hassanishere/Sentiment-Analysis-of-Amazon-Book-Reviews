{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533b4f95-2f19-4ff9-95f2-15a208be4560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviewText  overall\n",
      "0     This is one my must have books. It is a master...      4.0\n",
      "1     This book provides a reflection that you can a...      4.0\n",
      "2     I first read THE PROPHET in college back in th...      4.0\n",
      "3     A timeless classic.  It is a very demanding an...      4.0\n",
      "4     Reading this made my mind feel like a still po...      4.0\n",
      "...                                                 ...      ...\n",
      "1021  To make my point I'll be as concise as possibl...      0.0\n",
      "1022  This is a book that I can't put down, until 2 ...      3.0\n",
      "1023  I started this book with the idea that it woul...      3.0\n",
      "1024  This novel was beautifully written.  Amy Tan o...      3.0\n",
      "1025  The Professor and the Madman deals with the ro...      3.0\n",
      "\n",
      "[1026 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'path_to_file' with the actual path to your file\n",
    "df = pd.read_csv('mini_sample.xls')\n",
    "\n",
    "df = df[['reviewText', 'overall']]\n",
    "df['overall'] = df['overall'] - 1  # Adjust labels to start from 0\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe54b24-e0f9-4d7d-9b55-7db876d6597c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'overall' column: int64\n"
     ]
    }
   ],
   "source": [
    "df['overall'] = df['overall'].astype(int)\n",
    "# Using the dtype attribute\n",
    "overall_dtype = df['overall'].dtype\n",
    "print(\"Data type of 'overall' column:\", overall_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09178528-2706-4001-bdde-ed9b7faa0f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to MINI_SAMPLE.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the path where you want to save the CSV file\n",
    "file_path = \"MINI_SAMPLE.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)  # Set index=False to exclude row indices in the CSV\n",
    "\n",
    "print(f\"DataFrame saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b1fcf2-e635-437e-bd01-b55cb172dfdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (3.12.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (0.22.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c7d7b9-6103-495a-92c7-df2c0f1ecdb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13c159651f54c18a53f7e51517edc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"csv\", data_files=\"MINI_SAMPLE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92777ed-4bc8-4355-acfd-3b3eae23d74e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['reviewText', 'overall'],\n",
       "        num_rows: 1026\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a67cafa-be1f-4ce3-9114-1dc9a9556487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import DatasetDict\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "# Assuming 'dataset' is your DatasetDict object containing the training split\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "# Split the training dataset into train and test sets\n",
    "train_data, val_data = train_test_split(train_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the splits to Dataset objects\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "\n",
    "# Now you have train_dataset and test_dataset containing the training and test data\n",
    "\n",
    "# Create a new DatasetDict object to hold the splits\n",
    "split_dataset = DatasetDict({'train': train_dataset, 'validation': val_dataset})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10cb050-566b-4cc8-b8c3-a55fe5287094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['reviewText', 'overall'],\n",
       "        num_rows: 820\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['reviewText', 'overall'],\n",
       "        num_rows: 206\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c31ea772-bd1c-4763-86e4-011760879bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (4.39.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (4.65.0)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (2.0.0.post200)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from torch->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->transformers[torch]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->transformers[torch]) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f81d474-2dd9-4dbb-8eb4-0d89b638dfc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a35359d4d304fcf97903dd3912be5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/820 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237f350608384bbf977b5f511900ca02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/206 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# Assuming you have a DatasetDict object named dataset_dict\n",
    "# and you want to apply the map function to the 'train' dataset\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"reviewText\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Now you can use the .map() method on the train_dataset\n",
    "tokenized_datasets = split_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2feb69ae-0d3f-4832-bf85-5416fd1ce44e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['reviewText', 'overall', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 820\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['reviewText', 'overall', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 206\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda656b3-1671-4d11-9cbc-67616378b1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"reviewText\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"overall\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e69324a2-cdc2-4b7f-9620-d9802bd08c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 820\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 206\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74901ec3-9de8-4550-a6fe-1868824e62b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"]\n",
    "small_eval_dataset = tokenized_datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df7ec239-6572-4bc0-b5f7-086fbcd7c7af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=3)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b21ceb-a39e-43cc-97a5-9e81e4ac6b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6113c116-c366-47d6-99a0-8893fdf50a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "256887c9-5135-4e5b-a53b-b98cd2393005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37f96dfc-9864-478a-af95-6b01aeb9bfeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e88e478e-d776-460a-b9ba-e38e5c881450",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ebaf01eff646e6842d1bfa3e496221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/822 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7176e9ab-1873-4e94-afdb-807a32a5afdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7281553398058253}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
